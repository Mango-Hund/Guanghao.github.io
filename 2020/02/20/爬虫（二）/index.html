<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.jpg">
  <link rel="icon" type="image/png" href="/img/favicon.jpg">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  <title>爬虫（二） - Liu&#39;s blog</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Hao-Space</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/escape_velocity.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2020-02-20 21:40">
      2020年2月20日 晚上
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      3.3k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      47
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <h3 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h3><p>regular expression regex  RE<br>正则表达式是用来简洁表达一组字符串的表达式<br>优点是简洁<br><img src="/img/Crawler/22.png" srcset="/img/loading.gif" alt="图22"><br>是一种通用的字符串表达框架<br>简洁表达一组字符串的表达式<br>针对字符串表达“简洁”和“特征”思想的工具<br>判断字符串的特征归属<br>用处<br>表达文本类型的特征（病毒、入侵）<br>同时查找或替换一组字符串<br>匹配字符串的全部或部分<br>使用<br>编译：将符合正则表达式语法的字符串转换成正则表达式特征<br>语法<br>正则表达式是由字符和操作符组成<br><img src="/img/Crawler/23.png" srcset="/img/loading.gif" alt="图23"><br><img src="/img/Crawler/24.png" srcset="/img/loading.gif" alt="图24"><br>RE库是python的标准库，主要用于字符串的匹配 <code>import re</code><br>正则表达式的表示类型<br><code>raw string</code>类型（原生字符串类型）<br>re库采用raw string类型表示正则表达式，表示为：<code>r &#39;text&#39;</code> 例如<code>r&#39;[1-9]\d{5}&#39;</code><br>原生字符串不包含转义符<br><img src="/img/Crawler/26.png" srcset="/img/loading.gif" alt="图26"><br>re.search(pattern,string,flag=0)<br>在一个字符串中搜索匹配正则表达式的第一个位置，返回match对象  </p>
<ul>
<li>pattern：正则表达式的字符串或原生字符串表示  </li>
<li>string：待匹配的字符串  </li>
<li>flags：正则表达式使用时的控制标记<br><img src="/img/Crawler/27.png" srcset="/img/loading.gif" alt="图27">  <pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> re
<span class="hljs-meta">&gt;&gt;&gt; </span>match = re.search(<span class="hljs-string">r'[1-9]\d&#123;5&#125;'</span>, <span class="hljs-string">'BIT 100081'</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">if</span> match:
<span class="hljs-meta">... </span>    print(match.group(<span class="hljs-number">0</span>))<span class="hljs-comment">#group() 同group（0）就是匹配正则表达式整体结果</span>
<span class="hljs-meta">... </span>
<span class="hljs-number">100081</span></code></pre>
<code>re.match(pattern,string,flags=0)</code><br>从一个字符串的开始位置匹配正则表达式，返回match对象。  </li>
<li>pattern：正则表达式的字符串或原生字符串表示  </li>
<li>string：待匹配的字符串  </li>
<li>flags：正则表达式使用时的控制标记  <pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> re
<span class="hljs-meta">&gt;&gt;&gt; </span>match = re.search(<span class="hljs-string">r'[1-9]\d&#123;5&#125;'</span>, <span class="hljs-string">'BIT 100081'</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">if</span> match:
<span class="hljs-meta">... </span>    print(match.group(<span class="hljs-number">0</span>))
<span class="hljs-meta">... </span>
<span class="hljs-number">100081</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> re
<span class="hljs-meta">&gt;&gt;&gt; </span>match = re.match(<span class="hljs-string">r'[1-9]\d&#123;5&#125;'</span>, <span class="hljs-string">'BLT 100081'</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">if</span> match:
<span class="hljs-meta">... </span>    match.group[<span class="hljs-number">0</span>]
<span class="hljs-meta">... </span>
<span class="hljs-meta">&gt;&gt;&gt; </span>match = re.match(<span class="hljs-string">r'[1-9]\d&#123;5&#125;'</span>, <span class="hljs-string">'100081 BLT'</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">if</span> match:
<span class="hljs-meta">... </span>    match.group(<span class="hljs-number">0</span>)
<span class="hljs-meta">... </span>
<span class="hljs-string">'100081'</span></code></pre>
<code>re.findall(pattern,string,flags=0)</code><br>搜索字符串，以列表类型返回所有能匹配的子串  </li>
<li>pattern：正则表达式的字符串或原生字符串表示  </li>
<li>string：待匹配的字符串  </li>
<li>flags：正则表达式使用时的控制标记  <pre><code class="hljs python"> &gt;&gt;&gt; <span class="hljs-keyword">import</span> re
<span class="hljs-meta">&gt;&gt;&gt; </span>ls = re.findall(<span class="hljs-string">r'[1-9]\d&#123;5&#125;'</span>, <span class="hljs-string">'BIL100081 TSU100025'</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ls
[<span class="hljs-string">'100081'</span>, <span class="hljs-string">'100025'</span>]</code></pre>
<code>re.split(pattern,string,maxsplit=0,flags=0)</code><br>将一个字符串按照正则表达式匹配的结果进行分割，返回列表类型  </li>
<li>pattern：正则表达式的字符串或原生字符串表示  </li>
<li>string：待匹配的字符串  </li>
<li>flags：正则表达式使用时的控制标记  </li>
<li>maxspilt: 最大分割数，剩余部分作为最后一个元素输出  <pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> re
<span class="hljs-meta">&gt;&gt;&gt; </span>ls = re.split(<span class="hljs-string">r'[1-9]\d&#123;5&#125;'</span>, <span class="hljs-string">'BIL100081 TSU100025'</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ls
[<span class="hljs-string">'BIL'</span>, <span class="hljs-string">' TSU'</span>, <span class="hljs-string">''</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>ls = re.split(<span class="hljs-string">r'[1-9]\d&#123;5&#125;'</span>, <span class="hljs-string">'BIL100081 TSU100025'</span>, maxsplit=<span class="hljs-number">1</span>) 
<span class="hljs-meta">&gt;&gt;&gt; </span>ls
[<span class="hljs-string">'BIL'</span>, <span class="hljs-string">' TSU100025'</span>]</code></pre>
<code>re.finditer(pattern,string,flags=0)</code><br>搜索字符串，返回一个匹配结果的迭代类型，每个迭代元素是match对象  </li>
<li>pattern：正则表达式的字符串或原生字符串表示  </li>
<li>string：待匹配的字符串  </li>
<li>flags：正则表达式使用时的控制标记<pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> re
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> re.finditer(<span class="hljs-string">r'[1-9]\d&#123;5&#125;'</span>, <span class="hljs-string">'BIT100081 TSU100084'</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">if</span> m:
<span class="hljs-meta">... </span>            print(m.group(<span class="hljs-number">0</span>))
<span class="hljs-meta">... </span>
<span class="hljs-number">100081</span>
<span class="hljs-number">100084</span></code></pre>
<code>re.sub(pattern,repl,string,count=0,flags=0)</code><br>在一个字符串中替换所有匹配正则表达式的子串，返回替换后的字符串</li>
<li>pattern：正则表达式的字符串或原生字符串表示</li>
<li>repl: 替换字符串的字符串</li>
<li>string：待匹配的字符串</li>
<li>count：匹配的最大替换次数</li>
<li>flags：正则表达式使用时的控制标记<pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> re
<span class="hljs-meta">&gt;&gt;&gt; </span>re,sub(<span class="hljs-string">r'[1-9]\d&#123;5&#125;'</span>, <span class="hljs-string">':zipcode'</span>, <span class="hljs-string">'BLT100081 TSU100084'</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>re.sub(<span class="hljs-string">r'[1-9]\d&#123;5&#125;'</span>, <span class="hljs-string">':zipcode'</span>, <span class="hljs-string">'BLT100081 TSU100084'</span>)
<span class="hljs-string">'BLT:zipcode TSU:zipcode'</span></code></pre>
<img src="/img/Crawler/28.png" srcset="/img/loading.gif" alt="图28"><br><code>egex = re.compile(pattern,flags=0)</code><br>将正则表达式的字符串形式编译成正则表达式对象<br>*pattern：正则表达式的字符串或原生字符串表示  </li>
</ul>
<p>*flags ：正则表达式使用时的控制标记<br>RE库的match对象<br><pre><code class="hljs python">RE库的match对象  
﻿&gt;&gt;&gt; <span class="hljs-keyword">import</span> re
<span class="hljs-meta">&gt;&gt;&gt; </span>match = re.search(<span class="hljs-string">r'[1-9]\d&#123;5&#125;'</span>, <span class="hljs-string">'BLT 100081'</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">if</span> match:
<span class="hljs-meta">... </span>    print(match.group(<span class="hljs-number">0</span>))
<span class="hljs-meta">... </span>
<span class="hljs-number">100081</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>typr(match)
<span class="hljs-meta">&gt;&gt;&gt; </span>type(match)
&lt;<span class="hljs-class"><span class="hljs-keyword">class</span> '<span class="hljs-title">_sre</span>.<span class="hljs-title">SRE_Match</span>'&gt;</span></code></pre><br><img src="/img/Crawler/29.png" srcset="/img/loading.gif" alt="图29"><br><img src="/img/Crawler/30.png" srcset="/img/loading.gif" alt="图30"><br><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> re
<span class="hljs-meta">&gt;&gt;&gt; </span>m = re.search(<span class="hljs-string">r'[1-9]\d'</span>, <span class="hljs-string">'BIT100081 TSU100084'</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>m.string
<span class="hljs-string">'BIT100081 TSU100084'</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m.re
re.compile(<span class="hljs-string">'[1-9]\\d'</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>m.pos
<span class="hljs-number">0</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m.endpos
<span class="hljs-number">19</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m.end()
<span class="hljs-number">5</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m.start()
<span class="hljs-number">3</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m.span()
(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>)</code></pre><br>RE库的贪婪匹配和最小匹配<br><pre><code class="hljs awk">match = re.search(<span class="hljs-string">r'PY.*N'</span>, <span class="hljs-string">'PYANBNCNDN'</span> 
match.group(<span class="hljs-number">0</span>) <span class="hljs-comment">#re库默认采用贪婪匹配，即输出匹配最长的子串</span>
match = re.search(<span class="hljs-string">r'PY.*？N'</span>, <span class="hljs-string">'PYANBNCNDN'</span>) <span class="hljs-comment">#输出最小的匹配</span></code></pre><br><img src="/img/Crawler/31.png" srcset="/img/loading.gif" alt="图31">  </p>
<h4 id="淘宝商店比价定向爬虫"><a href="#淘宝商店比价定向爬虫" class="headerlink" title="淘宝商店比价定向爬虫"></a>淘宝商店比价定向爬虫</h4><p>功能描述<br>目标：获取淘宝搜索页面的信息，提取其中的商品名称和价格。<br>理解：<br>淘宝的搜索接口<br>翻页的处理<br>技术路线：requests-re   </p>
<p>程序的结构设计<br>步骤1：提交商品搜索请求，循环获取页面<br>步骤2：对于每个页面，提取商品名称和价格信息<br>步骤3：将信息输出到屏幕上<br><pre><code class="hljs python">
<span class="hljs-comment">#CrowTaobaoPrice.py</span>
<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">import</span> re
 
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getHTMLText</span><span class="hljs-params">(url)</span>:</span>
    <span class="hljs-keyword">try</span>:
        r = requests.get(url, timeout=<span class="hljs-number">30</span>)
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        <span class="hljs-keyword">return</span> r.text
    <span class="hljs-keyword">except</span>:
        <span class="hljs-keyword">return</span> <span class="hljs-string">""</span>
     
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parsePage</span><span class="hljs-params">(ilt, html)</span>:</span>
    <span class="hljs-keyword">try</span>:
        plt = re.findall(<span class="hljs-string">r'\"view_price\"\:\"[\d\.]*\"'</span>,html)
        tlt = re.findall(<span class="hljs-string">r'\"raw_title\"\:\".*?\"'</span>,html)
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(plt)):
            price = eval(plt[i].split(<span class="hljs-string">':'</span>)[<span class="hljs-number">1</span>])
            title = eval(tlt[i].split(<span class="hljs-string">':'</span>)[<span class="hljs-number">1</span>])
            ilt.append([price , title])
    <span class="hljs-keyword">except</span>:
        print(<span class="hljs-string">""</span>)
 
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">printGoodsList</span><span class="hljs-params">(ilt)</span>:</span>
    tplt = <span class="hljs-string">"&#123;:4&#125;\t&#123;:8&#125;\t&#123;:16&#125;"</span>
    print(tplt.format(<span class="hljs-string">"序号"</span>, <span class="hljs-string">"价格"</span>, <span class="hljs-string">"商品名称"</span>))
    count = <span class="hljs-number">0</span>
    <span class="hljs-keyword">for</span> g <span class="hljs-keyword">in</span> ilt:
        count = count + <span class="hljs-number">1</span>
        print(tplt.format(count, g[<span class="hljs-number">0</span>], g[<span class="hljs-number">1</span>]))
         
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span><span class="hljs-params">()</span>:</span>
    goods = <span class="hljs-string">'火影忍者'</span>
    depth = <span class="hljs-number">3</span>
    start_url = <span class="hljs-string">'https://s.taobao.com/search?spm=a21bo.2017.201867-links-7.37.5af911d9AriixI&amp;q='</span> + goods
    infoList = []
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(depth):
        <span class="hljs-keyword">try</span>:
            url = start_url + <span class="hljs-string">'&amp;s='</span> + str(<span class="hljs-number">44</span>*i)
            html = getHTMLText(url)
            parsePage(infoList, html)
        <span class="hljs-keyword">except</span>:
            <span class="hljs-keyword">continue</span>
    printGoodsList(infoList)
     
main()</code></pre></p>
<h4 id="股票数据定向爬虫"><a href="#股票数据定向爬虫" class="headerlink" title="股票数据定向爬虫"></a>股票数据定向爬虫</h4><p>目标：获取上交所和深交所所有股票的名称和交易信息<br>输出：保存到文件中<br>技术路线：requests-bs4-re<br>选取原则：股票信息静态存在于HTML页面中，非js代码生成，没有robots协议限制<br>选取方法：浏览器F12，源代码查看等<br>选取心态：不要纠结于某个网站，多找信息源尝试<br>程序的结构设计<br>步骤1：从东方财富网获取股票列表<br>步骤2：根据股票列表逐个到百度股票获取个股信息<br>步骤3：将结果存储到文件<br><pre><code class="hljs python"><span class="hljs-comment">#CrawBaiduStocksB.py</span>
<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup
<span class="hljs-keyword">import</span> traceback
<span class="hljs-keyword">import</span> re
 
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getHTMLText</span><span class="hljs-params">(url, code=<span class="hljs-string">"utf-8"</span>)</span>:</span>
    <span class="hljs-keyword">try</span>:
        r = requests.get(url)
        r.raise_for_status()
        r.encoding = code
        <span class="hljs-keyword">return</span> r.text
    <span class="hljs-keyword">except</span>:
        <span class="hljs-keyword">return</span> <span class="hljs-string">""</span>
 
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getStockList</span><span class="hljs-params">(lst, stockURL)</span>:</span>
    html = getHTMLText(stockURL, <span class="hljs-string">"GB2312"</span>)
    soup = BeautifulSoup(html, <span class="hljs-string">'html.parser'</span>) 
    a = soup.find_all(<span class="hljs-string">'a'</span>)
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> a:
        <span class="hljs-keyword">try</span>:
            href = i.attrs[<span class="hljs-string">'href'</span>]          <span class="hljs-comment">#&lt;a&gt; 标签的 href 属性用于指定超链接目标的 URL</span>
            lst.append(re.findall(<span class="hljs-string">r"[s][hz]\d&#123;6&#125;"</span>, href)[<span class="hljs-number">0</span>])
        <span class="hljs-keyword">except</span>:
            <span class="hljs-keyword">continue</span>
 
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getStockInfo</span><span class="hljs-params">(lst, stockURL, fpath)</span>:</span>
    count = <span class="hljs-number">0</span>
    <span class="hljs-keyword">for</span> stock <span class="hljs-keyword">in</span> lst:
        url = stockURL + stock + <span class="hljs-string">".html"</span>
        html = getHTMLText(url)
        <span class="hljs-keyword">try</span>:
            <span class="hljs-keyword">if</span> html==<span class="hljs-string">""</span>:
                <span class="hljs-keyword">continue</span>
            infoDict = &#123;&#125;
            soup = BeautifulSoup(html, <span class="hljs-string">'html.parser'</span>)
            stockInfo = soup.find(<span class="hljs-string">'div'</span>,attrs=&#123;<span class="hljs-string">'class'</span>:<span class="hljs-string">'stock-bets'</span>&#125;)
 
            name = stockInfo.find_all(attrs=&#123;<span class="hljs-string">'class'</span>:<span class="hljs-string">'bets-name'</span>&#125;)[<span class="hljs-number">0</span>]
            infoDict.update(&#123;<span class="hljs-string">'股票名称'</span>: name.text.split()[<span class="hljs-number">0</span>]&#125;)
             
            keyList = stockInfo.find_all(<span class="hljs-string">'dt'</span>)
            valueList = stockInfo.find_all(<span class="hljs-string">'dd'</span>)
            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(keyList)):
                key = keyList[i].text
                val = valueList[i].text
                infoDict[key] = val
             
            <span class="hljs-keyword">with</span> open(fpath, <span class="hljs-string">'a'</span>, encoding=<span class="hljs-string">'utf-8'</span>) <span class="hljs-keyword">as</span> f:
                f.write( str(infoDict) + <span class="hljs-string">'\n'</span> )
                count = count + <span class="hljs-number">1</span>
                print(<span class="hljs-string">"\r当前进度: &#123;:.2f&#125;%"</span>.format(count*<span class="hljs-number">100</span>/len(lst)),end=<span class="hljs-string">""</span>)
        <span class="hljs-keyword">except</span>:
            count = count + <span class="hljs-number">1</span>
            print(<span class="hljs-string">"\r当前进度: &#123;:.2f&#125;%"</span>.format(count*<span class="hljs-number">100</span>/len(lst)),end=<span class="hljs-string">""</span>)print(<span class="hljs-string">'*'</span>,end = <span class="hljs-string">' '</span>)
            <span class="hljs-comment">#end值为空格</span>
            <span class="hljs-comment">#print('*',end = '')#end值为空字符串</span>
            <span class="hljs-comment">#print('*',end = '')#end值为空字符串</span>
            <span class="hljs-comment">#print('')#end值为默认值（换行\n）</span>
            <span class="hljs-comment">#print('*',end = '1')#end值为字符串‘1’</span>
            <span class="hljs-comment">#print('*',end = '12')#end值为字符串‘12’</span>
            <span class="hljs-keyword">continue</span>
 
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span><span class="hljs-params">()</span>:</span>
    stock_list_url = <span class="hljs-string">'https://quote.eastmoney.com/stocklist.html'</span>
    stock_info_url = <span class="hljs-string">'https://gupiao.baidu.com/stock/'</span>
    output_file = <span class="hljs-string">'D:/BaiduStockInfo.txt'</span>
    slist=[]
    getStockList(slist, stock_list_url)
    getStockInfo(slist, stock_info_url, output_file)
 
main()</code></pre></p>
<h3 id="Scrapy-框架与实例"><a href="#Scrapy-框架与实例" class="headerlink" title="Scrapy 框架与实例"></a>Scrapy 框架与实例</h3><p>Scrapy是功能强大的爬虫框架<br>爬虫框架是实现爬虫功能的一个软件结构和功能组件集合<br>爬虫框架是一个半成品，能够帮助用户实现专业网络爬虫<br>Scrapy爬虫框架结构：<br><img src="/img/Crawler/32.png" srcset="/img/loading.gif" alt="图32"><br><code>Downloader Middleware</code><br>目的：实施Engine、Scheduler和Downlaoder之间进行用户可配置的控制<br>功能：修改、丢弃、新增请求或者响应<br><code>Spider</code>（用户主要编写模块）<br>解析Downloader返回的响应（Response）<br>产生爬取项（scrapyed item）<br>产生额外的爬取请求（Requests）<br><code>Item Pipelines</code>（需要用户自己编写代码）<br>以流水线方式处理Spider产生的爬取项<br>由一组操作顺序组成，类似流水线，每个操作是一个Item Pipeline类型<br>可能操作包括：清理、检验和查重爬取项中的HTML数据、将数据存储到数据库<br><code>Spider Middleware</code><br>目的：对请求和爬取项的再处理<br>功能：修改、丢弃、新增请求或者爬取项<br>用户可以编写配置代码<br><img src="/img/Crawler/33.png" srcset="/img/loading.gif" alt="图33"><br>Scrapy命令行格式：<br><code>&gt;scrapy&lt;command&gt;[options][args]</code><br><img src="/img/Crawler/34.png" srcset="/img/loading.gif" alt="图34"><br>产生步骤：  </p>
<ol>
<li>建立一个Scapy爬虫工程  </li>
<li>在工程中产生一个Scrapy爬虫  </li>
<li>配置产生的spider爬虫  </li>
<li>运行爬虫，获取网页  <pre><code class="hljs livecodeserver">oot@liu-PC:/home/liu/Documents/learn<span class="hljs-comment"># scrapy startproject scrapydemo</span>
New Scrapy project <span class="hljs-string">'scrapydemo'</span>, <span class="hljs-keyword">using</span> template <span class="hljs-built_in">directory</span> <span class="hljs-string">'/usr/lib/python3/dist-packages/scrapy/templates/project'</span>, created <span class="hljs-keyword">in</span>:
 /home/liu/Documents/learn/scrapydemo
You can <span class="hljs-built_in">start</span> your <span class="hljs-keyword">first</span> spider <span class="hljs-keyword">with</span>:
 cd scrapydemo
 scrapy genspider example example.com
root@liu-PC:/home/liu/Documents/learn<span class="hljs-comment"># cd scrapydemo/</span>
root@liu-PC:/home/liu/Documents/learn/scrapydemo<span class="hljs-comment"># scrapy genspider demo python123.io</span>
Created spider <span class="hljs-string">'demo'</span> <span class="hljs-keyword">using</span> template <span class="hljs-string">'basic'</span> <span class="hljs-keyword">in</span> module:
 scrapydemo.spiders.demo﻿​</code></pre>
<pre><code class="hljs python"> -*- coding: utf<span class="hljs-number">-8</span> -*-
<span class="hljs-keyword">import</span> scrapy


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DemoSpider</span><span class="hljs-params">(scrapy.Spider)</span>:</span>
    name = <span class="hljs-string">'demo'</span>
    <span class="hljs-comment">#allowed_domains = ['python123.io']</span>
    start_urls = [<span class="hljs-string">'http://python123.io/ws/demo.html'</span>]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span>
        fname = response.url.split(<span class="hljs-string">'/'</span>)[<span class="hljs-number">-1</span>]
        <span class="hljs-keyword">with</span> open(fname, <span class="hljs-string">'wb'</span>) <span class="hljs-keyword">as</span> f:
            f.write(response.body)
        self.log(<span class="hljs-string">'Saved file %s.'</span> % name)</code></pre>
<code>scrapy crawl  demo</code>运行爬虫<br>parse()用于处理响应，解析内容形成字典，发现新的URL爬取请求</li>
</ol>
<h4 id="Yield关键字"><a href="#Yield关键字" class="headerlink" title="Yield关键字"></a>Yield关键字</h4><p>生成器是一个不断产生值的函数<br>包含yield语句的函数是一个生成器<br>生成器每次产生一个值（yield语句），函数被冻结，被唤醒后再产生一个值<br><pre><code class="hljs ruby"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gen</span><span class="hljs-params">(n)</span></span><span class="hljs-symbol">:</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n)<span class="hljs-symbol">:</span>
        <span class="hljs-keyword">yield</span> i**<span class="hljs-number">2</span>
        <span class="hljs-comment">#产生一个小于n的所有整数的平方值</span></code></pre><br>生成器相比一次列出所有内容的优势<br>更节省存储空间<br>响应更迅速<br>使用更灵活  </p>
<p>Scrapy爬虫的使用步骤：<br>步骤1：创建一个工程和Spider模板<br>步骤2：编写Spider<br>步骤3：编写Item Pipeline<br>步骤4：优化配置策略  </p>
<p>爬虫的数据类型：Request 类、Response类、Item类<br>Request类 <code>class scrapy.http.Request()</code><br>Request对象表示一个HTTP请求<br>由spider生成，由Downlaoder执行  </p>
<ul>
<li>url               Request对应请求的URL地址</li>
<li>method       对应的请求方法， ‘GET’ ‘POST’等</li>
<li>header        字典类型风格的请求头</li>
<li>body           请求内容主体，字符串类型</li>
<li>meta           用户添加的扩展信息，在Scrapy内部模块间传递信息使用  </li>
<li>copy()         复制该请求  </li>
</ul>
<p><code>Response类 class scrapy.http.Response()</code><br>Response对象表示一个HTTP响应<br>由Downlaoder生成，由spider处理  </p>
<ul>
<li>url               Request对应请求的URL地址</li>
<li>status         HTTP状态码，默认是200</li>
<li>header       Response对应的头部信息</li>
<li>body           Response对应的内容主体信息，字符串类型</li>
<li>flag             一组标记</li>
<li>request       产生Response类型对应的Request对象</li>
<li>copy()         复制该响应</li>
</ul>
<p>Item类 <code>class scrapy.item.Item()</code><br>Item对象表示一个从HTML页面中提取的信息内容<br>由Spider生成，由Item Pipeline处理<br>Item类似于字典类型，可以按照字典类型操作  </p>
<p>Scrapy爬虫支持多种HTML信息提取方法<br>Beautiful Soup<br>Ixml<br>re<br>XPath Selector<br>CSS Selector  </p>
<p><code>&lt;HTML&gt;.css(&#39;a::attr(href)&#39;).extract</code>  # a:标签名称  href：标签属性</p>
<h4 id="股票数据Scrapy爬虫实例"><a href="#股票数据Scrapy爬虫实例" class="headerlink" title="股票数据Scrapy爬虫实例"></a>股票数据Scrapy爬虫实例</h4><p>功能描述：<br>技术路线：Scrapy<br>目标：获取上交所和深交所所有股票的名称和交易信息<br>输出：保存到文件中   </p>
<p>获取股票列表：<br>东方财富网：<a href="http://quote.eastmoney.com/stocklist.html" target="_blank" rel="noopener">http://quote.eastmoney.com/stocklist.html</a><br>获取个股信息：<br>百度股票： <a href="https://gupiao.baidu.com/stock/" target="_blank" rel="noopener">https://gupiao.baidu.com/stock/</a><br>单个股票：<a href="https://gupiao.baidu.com/stock/sz002439.html" target="_blank" rel="noopener">https://gupiao.baidu.com/stock/sz002439.html</a><br>步骤：<br>1.建立工程和Spider模板<br><pre><code class="hljs armasm"><span class="hljs-symbol">scrapy</span> startproject <span class="hljs-keyword">BaiduStocks</span>
<span class="hljs-keyword">cd </span><span class="hljs-keyword">BaiduStocks</span>
<span class="hljs-keyword">scrapy </span>genspider stocks <span class="hljs-keyword">baidu.com</span>
<span class="hljs-keyword">进一步修改spider/stocks.py文件</span></code></pre><br>2.编写Spider<br>配置stocks.py文件<br>修改对返回页面的处理<br>修改对新增URL爬取请求的处理<br><pre><code class="hljs python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span>
<span class="hljs-keyword">import</span> scrapy
<span class="hljs-keyword">import</span> re

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">StocksSpider</span><span class="hljs-params">(scrapy.Spider)</span>:</span>
    name = <span class="hljs-string">'stocks'</span>
    start_urls = [<span class="hljs-string">'http://quote.eastmoney.com/stocklist.html'</span>]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span>
        <span class="hljs-keyword">for</span> href <span class="hljs-keyword">in</span> response.css(<span class="hljs-string">'a::attr(href)'</span>).extract():
            <span class="hljs-keyword">try</span>:
                stock = re.findall(<span class="hljs-string">r"[s][hz]\d&#123;6&#125;"</span>, href)[<span class="hljs-number">0</span>]
                url = <span class="hljs-string">'https://gupiao.baidu.com/stock'</span> + stock +<span class="hljs-string">'.html'</span>
                <span class="hljs-keyword">yield</span> scrapy.Request(url, callback=self.parse_stock)<span class="hljs-comment">#回调函数，异步进程</span>
            <span class="hljs-keyword">except</span>:
                <span class="hljs-keyword">continue</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_stock</span><span class="hljs-params">(self,response)</span>:</span>
        infoDict = &#123;&#125;
        stockInfo = response.css(<span class="hljs-string">'.stock-bets'</span>)
        name = stockInfo.css(<span class="hljs-string">'.bets-name'</span>).extract()[<span class="hljs-number">0</span>]
        keyList = stockInfo.css(<span class="hljs-string">'dt'</span>).extract()
        valueList = stockInfo.css(<span class="hljs-string">'dd'</span>).extract()
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(keyList)):
            key = re.findall(<span class="hljs-string">r'&gt;.*&lt;/d&gt;'</span>, keyList[i])[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>:<span class="hljs-number">-5</span>]
            <span class="hljs-keyword">try</span>:
                val = re.findall(<span class="hljs-string">r'\d+\.?.*&lt;/dd&gt;'</span>, valueList[i])[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>:<span class="hljs-number">-5</span>]
            <span class="hljs-keyword">except</span>:
                val = <span class="hljs-string">'--'</span>
            infoDict[key]=val

        infoDict.update(
            &#123;<span class="hljs-string">'股票名称'</span>:re.findall(<span class="hljs-string">'\s.*\('</span>,name)[<span class="hljs-number">0</span>].split()[<span class="hljs-number">0</span>] +\
            re.findall(<span class="hljs-string">'\&gt;.*\&lt;'</span>, name)[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>:<span class="hljs-number">-1</span>]&#125;)
        <span class="hljs-keyword">yield</span> infoDict</code></pre><br>3.编写ITEM Pipelines<br>配置pipelines.py文件<br>定义对爬取项（Scraped Item）的处理类<br><pre><code class="hljs ruby">
<span class="hljs-comment"># -*- coding: utf-8 -*-</span>

<span class="hljs-comment"># Define your item pipelines here</span>
<span class="hljs-comment">#</span>
<span class="hljs-comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span>
<span class="hljs-comment"># See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span>


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BaidustocksPipeline</span>(<span class="hljs-title">object</span>):</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_item</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, item, spider)</span></span><span class="hljs-symbol">:</span>
        <span class="hljs-keyword">return</span> item

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BaidustocksInfoPipeline</span>(<span class="hljs-title">object</span>):</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">open_spider</span><span class="hljs-params">(<span class="hljs-keyword">self</span>,spider)</span></span><span class="hljs-symbol">:</span>
        <span class="hljs-keyword">self</span>.f = open(<span class="hljs-string">'BaiduStockInfo.txt'</span>, <span class="hljs-string">'w'</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">close_spider</span><span class="hljs-params">(<span class="hljs-keyword">self</span>,spider)</span></span><span class="hljs-symbol">:</span>
        <span class="hljs-keyword">self</span>.f.close()
    
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_item</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, item, spider)</span></span><span class="hljs-symbol">:</span>
        <span class="hljs-symbol">try:</span>
            line = str(dict(item)) + <span class="hljs-string">'\n'</span>
            <span class="hljs-keyword">self</span>.f.write(line)
        <span class="hljs-symbol">except:</span>
            pass
        <span class="hljs-keyword">return</span> item</code></pre><br>配置ITEM_PIPELINES选项<br><pre><code class="hljs ebnf"><span class="hljs-attribute">ITEM_PIPELINES</span> = &#123;
    <span class="hljs-string">'BaiduStocks.pipelines.BaidustocksInfoPipeline'</span>: 300,
&#125;</code></pre></p>
<h4 id="优化实例"><a href="#优化实例" class="headerlink" title="优化实例"></a>优化实例</h4><p>配置并发连接选项<br><img src="/img/Crawler/35.png" srcset="/img/loading.gif" alt="图35"></p>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/study/">study</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Python/">Python</a>
                    
                      <a class="hover-with-bg" href="/tags/Crawler/">Crawler</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" target="_blank" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2020/03/03/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%80%EF%BC%89/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">数据分析工具（一）</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2020/02/15/%E7%88%AC%E8%99%AB%EF%BC%88%E4%B8%80%EF%BC%89/">
                        <span class="hidden-mobile">爬虫（一）</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "爬虫（二）&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





















<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"superSample":2,"width":150,"height":300,"position":"right","hOffset":0,"vOffset":-20},"mobile":{"show":true,"scale":0.5},"react":{"opacityDefault":0.7,"opacityOnHover":0.2},"log":false});</script></body>
</html>
